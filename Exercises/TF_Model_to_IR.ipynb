{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8b3720",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this tutorial lets understand how to convert TensorFlow* Object Detection API Models to the OpenVINO™ toolkit Intermediate represenstation (IR) format. For detailed explanation refer [Converting TensorFlow Object Detection API Models](https://docs.openvinotoolkit.org/2021.1/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html).\n",
    "\n",
    "<br><div class=note><i><b>Note: </b>It is assumed that the server this sample is being run on is on the Intel® DevCloud for the Edge which has Jupyter* Notebook customizations and all the required libraries already installed.</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6cb991",
   "metadata": {},
   "source": [
    "# Download the model\n",
    "\n",
    "The Intel® Distribution of OpenVINO™ toolkit includes the [Model Downloader](http://docs.openvinotoolkit.org/latest/_tools_downloader_README.html) utility  to download some common inference models from the [Open Model Zoo](https://github.com/opencv/open_model_zoo). \n",
    "\n",
    "Run the following cell to run the Model Downloader utility with the `--print_all` argument to see all the available inference models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcbc93",
   "metadata": {},
   "source": [
    "\n",
    "Following cell will downlaod SSD MobileNet v2 public model from [Open Model Zoo](https://github.com/opencv/open_model_zoo) and extract in ssd_mobilenet_v2_coco folder in your working directory. The required model file is **ssd_mobilenet_v2_coco/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ccc5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!downloader.py --name ssd_mobilenet_v2_coco -o ssd_mobilenet_v2_coco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fab5c",
   "metadata": {},
   "source": [
    "# Convert the frozen TensorFlow* model to IR format:\n",
    "\n",
    "If you have already installed Intel® Distribution of OpenVINO™ toolkit in you local machine, Model Optimizer will abe available in \\<INSTALL_DIR\\>/deployment_tools/model_optimizer directory. To convert an TensorFlow* model you can use following command.\n",
    "\n",
    "python3 /<INSTALL_DIR\\>/deployment_tools/model_optimizer/mo.py /\n",
    "\n",
    "--input_model=\\<TensorFlow model path\\>/frozen_inference_graph.pb /\n",
    "\n",
    "--transformations_config /<INSTALL_DIR\\>/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json /\n",
    "\n",
    "--tensorflow_object_detection_api_pipeline_config \\<TensorFlow model path\\>/pipeline.config /\n",
    "\n",
    "--reverse_input_channels\n",
    "\n",
    "Here,\n",
    "- **--input_model:** Path for the input model\n",
    "- **--transformations_config:**  A subgraph replacement configuration json file with transformations description. For the models downloaded from the TensorFlow* Object Detection API zoo, you can find the configuration files in the <INSTALL_DIR>/deployment_tools/model_optimizer/extensions/front/tf directory.\n",
    "- **--tensorflow_object_detection_api_pipeline_config:**  A special configuration file that describes the topology hyper-parameters and structure of the TensorFlow* Object Detection API model. For the models downloaded from the TensorFlow* Object Detection API zoo, the configuration file is named pipeline.config. If you plan to train a model yourself, you can find templates for these files in the [models repository](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs).\n",
    "- **--reverse_input_channels:** The color channel order (RGB or BGR) of an input data should match the channel order of the model training dataset. Otherwise, inference results may be incorrect. If you convert a TensorFlow* Object Detection API model to use with the Inference Engine sample applications, you must specify the this parameter.\n",
    "\n",
    "For other Tensorflow* specific parameters refer [TensorFlow* Specific Conversion Parameters](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html#tensorflow_specific_conversion_params). \n",
    "Following cell will convert the model to IR format with FP32 precision. It might take few seconds to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9734317",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py --input_model=ssd_mobilenet_v2_coco/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb --transformations_config /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json --tensorflow_object_detection_api_pipeline_config ssd_mobilenet_v2_coco/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config --reverse_input_channels --data_type FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e7a34",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully created the IR files and learnt it was a very easy one time process. You now have an optimized model. We will use these optimized model(IR files) in the AI application for inferencing which will be done with the help of Inference Engine. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (OpenVINO 2021.4 LTS)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
